# awesome-offline-rl
This is a collection of research and review papers for **offline reinforcement learning (offline rl)**. Feel free to star and fork.


Maintainers:
- [Yuta Saito](http://usaito.github.io/) (Hanjuku-kaso Co., Ltd.)
- Haruka Kiyohara (Tokyo Institute of Technology)

We are looking for more contributors and maintainers! Please feel free to [pull requests](https://github.com/usaito/awesome-offline-rl/pulls).

```
format: **title** by authors. [links]
```

For any question, feel free to contact: saito@hanjuku-kaso.com


## Papers

### Review Papers

- **Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems** by Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu. [[arXiv2020](https://arxiv.org/abs/2005.01643)]

### Offline RL: Theory/Methods

- **Conservative Q-Learning for Offline Reinforcement Learning** by Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine. [[NeurIPS2020](https://papers.nips.cc/paper/2020/hash/0d2b2061826a5df3221116a5085a6052-Abstract.html)] [[website](https://sites.google.com/view/cql-offline-rl)]
- **Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction** by Aviral Kumar, Justin Fu, George Tucker,  and Sergey Levine. [[NeurIPS2019](https://papers.nips.cc/paper/2019/hash/c2073ffa77b5357a498057413bb09d3a-Abstract.html)] [[website](https://sites.google.com/view/bear-off-policyrl)]
### Offline RL: Benchmarks/Experiments

- **An Optimistic Perspective on Offline Reinforcement Learning** by Rishabh Agarwal, Dale Schuurmans, and Mohammad Norouzi. [[ICML2020](https://proceedings.icml.cc/paper/2020/hash/ab013ca67cf2d50796b0c11d1b8bc95d-Abstract.html)] [[website](https://offline-rl.github.io/)]
- **Large-scale Open Dataset, Pipeline, and Benchmark for Bandit Algorithms** by Yuta Saito, Shunsuke Aihara, Megumi Matsutani, and Yusuke Narita. [[arXiv2020](https://arxiv.org/abs/2008.07146)] [[software](https://github.com/st-tech/zr-obp)] [[public dataset](https://research.zozo.com/data.html)]

### Off-Policy Evaluation: Theory/Methods
#### Contextual Bandits

- **Optimal Off-Policy Evaluation from Multiple Logging Policies** by Nathan Kallus, Yuta Saito, and Masatoshi Uehara. [[arXiv2020](https://arxiv.org/abs/2010.11002)] [[code](https://github.com/CausalML/MultipleLoggers)]
- **Off-Policy Evaluation and Learning for External Validity under a Covariate Shift** by Masatoshi Uehara, Masahiro Kato, and Shota Yasui. [[NeurIPS2020](https://papers.nips.cc/paper/2020/hash/0084ae4bc24c0795d1e6a4f58444d39b-Abstract.html)]
- **Efficient Counterfactual Learning from Bandit Feedback** by Yusuke Narita, Shota Yasui, and Kohei Yata. [[AAAI2019](https://arxiv.org/abs/1809.03084)]
- **Optimal and Adaptive Off-policy Evaluation in Contextual Bandits** by Yu-Xiang Wang, Alekh Agarwal, and Miroslav Dudik. [[ICML2017](https://arxiv.org/abs/1612.01205)]
- **The Self-Normalized Estimator for Counterfactual Learning** by Adith Swaminathan and Thorsten Joachims. [[NeurIPS2015](https://papers.nips.cc/paper/2015/hash/39027dfad5138c9ca0c474d71db915c3-Abstract.html)]
-  **Doubly Robust Policy Evaluation and Optimization** by Miroslav Dud√≠k, Dumitru Erhan, John Langford, and Lihong Li. [[ICML2011](https://arxiv.org/abs/1503.02834)]
- **Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms** by Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. [[WSDM2011](https://dl.acm.org/doi/10.1145/1935826.1935878)]
#### Reinforcement Learning

- **Intrinsically Efficient, Stable, and Bounded Off-Policy Evaluation for Reinforcement Learning** by Nathan Kallus, Masatoshi Uehara. [[NeurIPS2019](https://arxiv.org/abs/1906.03735)]
- **More Robust Doubly Robust Off-policy Evaluation** by Mehrdad Farajtabar, Yinlam Chow, and Mohammad Ghavamzadeh. [[ICML2018](https://arxiv.org/abs/1802.03493)]

### Applications

### Open Source Software

## Workshops

- **Offline Reinforcement Learning Workshop (NeurIPS 2020)** [[website](https://offline-rl-neurips.github.io/)]
- **Virtual Conference on Reinforcement Learning for Real Life (RL4RealLife 2020)** [[website](https://sites.google.com/view/RL4RealLife)]

## Lectures
